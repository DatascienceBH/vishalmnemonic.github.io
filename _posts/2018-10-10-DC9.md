---
title: "Manipulating DataFrames with pandas"
date: 2018-10-05
tags: [python]
header:
  images:
excerpt: "Manipulating DataFrames with pandas"
---

## Positional and labeled indexing
Given a pair of label-based indices, sometimes it's necessary to find the corresponding positions. We will use the Pennsylvania election results again. The DataFrame is provided for us as election. Find x and y such that election.iloc[x, y] == election.loc['Bedford', 'winner']. That is, what is the row position of 'Bedford', and the column position of 'winner'? Remember that the first position in Python is 0, not 1! To answer this question, first explore the DataFrame using election.head() in the Python Shell and inspect it with our eyes.

```python
# Assign the row position of election.loc['Bedford']: x
x = 4
# Assign the column position of election['winner']: y
y = election.columns.get_loc('winner')
# Print the boolean equivalence
print(election.iloc[x, y] == election.loc['Bedford', 'winner'])
```

## Indexing and column rearrangement
There are circumstances in which it's useful to modify the order of your DataFrame columns. We do that now by extracting just two columns from the Pennsylvania election results DataFrame. Our job is to read the CSV file and set the index to 'county'. We'll then assign a new DataFrame by selecting the list of columns ['winner', 'total', 'voters']. The CSV file is provided to us in the variable filename.

```python
# Import pandas
import pandas as pd
# Read in filename and set the index: election
election = pd.read_csv(filename, index_col='county')
# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results
results = election[['winner', 'total', 'voters']]
# Print the output of results.head()
print(results.head())
```

## Slicing rows
The Pennsylvania US election results data set that we have been using so far is ordered by county name. This means that county names can be sliced alphabetically. In this exercise, we're going to perform slicing on the county names of the election DataFrame.

```python
# Slice the row labels 'Perry' to 'Potter': p_counties
p_counties =  election.loc['Perry':'Potter']
# Print the p_counties DataFrame
print(p_counties)
# Slice the row labels 'Potter' to 'Perry' in reverse order: p_counties_rev
p_counties_rev =  election.loc['Potter':'Perry':-1]
# Print the p_counties_rev DataFrame
print(p_counties_rev)
```

## Slicing columns
Similar to row slicing, columns can be sliced by value. In this exercise, our job is to slice column names from the Pennsylvania election results DataFrame using .loc[].

```python
# Slice the columns from the starting column to 'Obama': left_columns
left_columns = election.loc[:,:'Obama']

# Print the output of left_columns.head()
print(left_columns.head())
# Slice the columns from 'Obama' to 'winner': middle_columns
middle_columns = election.loc[:,'Obama':'winner']
# Print the output of middle_columns.head()
print(middle_columns.head())
# Slice the columns from 'Romney' to the end: 'right_columns'
right_columns = election.loc[:,'Romney':]
# Print the output of right_columns.head()
print(right_columns.head())
```

## Subselecting DataFrames with lists
We can use lists to select specific row and column labels with the .loc[] accessor. In this exercise, our job is to select the counties ['Philadelphia', 'Centre', 'Fulton'] and the columns ['winner','Obama','Romney'] from the election DataFrame, which has been pre-loaded with the index set to 'county'.

```python
# Create the list of row labels: rows
rows = ['Philadelphia', 'Centre', 'Fulton']
# Create the list of column labels: cols
cols = ['winner', 'Obama', 'Romney']
# Create the new DataFrame: three_counties
three_counties = election.loc[rows,cols]
# Print the three_counties DataFrame
print(three_counties)
```

## Thresholding data
In this exercise, we have provided the Pennsylvania election results and included a column called 'turnout' that contains the percentage of voter turnout per county. Our job is to prepare a boolean array to select all of the rows and columns where voter turnout exceeded 70%.

```python
# Create the boolean array: high_turnout
high_turnout = election.turnout>70
# Filter the election DataFrame with the high_turnout array: high_turnout_df
high_turnout_df = election[high_turnout]
# Print the high_turnout_results DataFrame
print(high_turnout_df)
```

## Filtering columns using other columns
The election results DataFrame has a column labeled 'margin' which expresses the number of extra votes the winner received over the losing candidate. This number is given as a percentage of the total votes cast. It is reasonable to assume that in counties where this margin was less than 1%, the results would be too-close-to-call. Our job is to use boolean selection to filter the rows where the margin was less than 1. We'll then convert these rows of the 'winner' column to np.nan to indicate that these results are too close to declare a winner.

```python
# Import numpy
import numpy as np  
# Create the boolean array: too_close
too_close = election.margin <1
# Assign np.nan to the 'winner' column where the results were too close to call
election.winner[too_close]= np.nan
# Print the output of election.info()
print(election.info())
```

## Filtering using NaNs
In certain scenarios, it may be necessary to remove rows and columns with missing data from a DataFrame. The .dropna() method is used to perform this action. We'll now practice using this method on a dataset obtained from [Vanderbilt University](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.html), which consists of data from passengers on the Titanic. Explore it in the IPython Shell and we will note that there are many NaNs. We will focus specifically on the 'age' and 'cabin' columns in this exercise. Our job is to use .dropna() to remove rows where any of these two columns contains missing data and rows where all of these two columns contain missing data. We'll also use the .shape attribute, which returns the number of rows and columns in a tuple from a DataFrame, or the number of rows from a Series, to see the effect of dropping missing values from a DataFrame.

```python
# Select the 'age' and 'cabin' columns: df
df = titanic[['age','cabin']]
# Print the shape of df
print(df.shape)
# Drop rows in df with how='any' and print the shape
print(df.dropna(how='any').shape)
# Drop rows in df with how='all' and print the shape
print(df.dropna(how='all').shape)
# Call .dropna() with thresh=1000 and axis='columns' and print the output of .info() from titanic
print(titanic.dropna(thresh=1000, axis='columns').info())
```

## Using apply() to transform a column
The .apply() method can be used on a pandas DataFrame to apply an arbitrary Python function to every element. In this exercise we'll take daily weather data in Pittsburgh in 2013 obtained from Weather Underground. Our job is to use the .apply() method to perform this conversion on the 'Mean TemperatureF' and 'Mean Dew PointF' columns of the weather DataFrame.

```python
# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius
def to_celsius(F):
    return 5/9*(F - 32)
# Apply the function over 'Mean TemperatureF' and 'Mean Dew PointF': df_celsius
df_celsius = weather[['Mean TemperatureF','Mean Dew PointF']].apply(to_celsius)
# Reassign the columns df_celsius
df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']
# Print the output of df_celsius.head()
print(df_celsius.head())
```

## Using .map() with a dictionary
The .map() method is used to transform values according to a Python dictionary look-up. In this exercise we'll practice this method while returning to working with the election DataFrame. Our job is to use a dictionary to map the values 'Obama' and 'Romney' in the 'winner' column to the values 'blue' and 'red', and assign the output to the new column 'color'.

```python
# Create the dictionary: red_vs_blue
red_vs_blue = {'Obama':'blue','Romney':'red'}
# Use the dictionary to map the 'winner' column to the new column: election['color']
election['color'] = election.winner.map(red_vs_blue)
# Print the output of election.head()
print(election.head())
```

## Using vectorized functions
When performance is paramount, we should avoid using .apply() and .map() because those constructs perform Python for-loops over the data stored in a pandas Series or DataFrame. By using vectorized functions instead, we can loop over the data at the same speed as compiled code (C, Fortran, etc.)! NumPy, SciPy and pandas come with a variety of vectorized functions (called Universal Functions or UFuncs in NumPy). We can even write your own vectorized functions, but for now we will focus on the ones distributed by NumPy and pandas. In this exercise we're going to import the zscore function from scipy.stats and use it to compute the deviation in voter turnout in Pennsylvania from the mean in fractions of the standard deviation. In statistics, the z-score is the number of standard deviations by which an observation is above the mean - so if it is negative, it means the observation is below the mean.

```python
# Import zscore from scipy.stats
from scipy.stats import zscore
# Call zscore with election['turnout'] as input: turnout_zscore
turnout_zscore =  zscore(election['turnout'])
# Print the type of turnout_zscore
print(type(turnout_zscore))
# Assign turnout_zscore to a new column: election['turnout_zscore']
election['turnout_zscore']=turnout_zscore
# Print the output of election.head()
print(election.head())
```

## Changing index of a DataFrame
As we saw in the previous exercise, indexes are immutable objects. This means that if you want to change or modify the index in a DataFrame, then you need to change the whole index. We will do this now, using a list comprehension to create the new index. A list comprehension is a succinct way to generate a list in one line. For example, the following list comprehension generates a list that contains the cubes of all numbers from 0 to 9: cubes = [i**3 for i in range(10)]. This is equivalent to the following code:
```
cubes = []
for i in range(10):
    cubes.append(i**3)
```
Before getting started, print the sales DataFrame in the IPython Shell and verify that the index is given by month abbreviations containing lowercase characters.

```python
# Create the list of new indexes: new_idx
new_idx = [str.upper(i) for i in sales.index]
# Assign new_idx to sales.index
sales.index = new_idx
# Print the sales DataFrame
print(sales)
```

## Changing index name labels
Notice that in the previous exercise, the index was not labeled with a name. In this exercise, we will set its name to 'MONTHS'. Similarly, if all the columns are related in some way, we can provide a label for the set of columns.

```python
# Assign the string 'MONTHS' to sales.index.name
sales.index.name = 'MONTHS'
# Print the sales DataFrame
print(sales)
# Assign the string 'PRODUCTS' to sales.columns.name
sales.columns.name= 'PRODUCTS'
# Print the sales dataframe again
print(sales)
```

## Building an index, then a DataFrame
We can also build the DataFrame and index independently, and then put them together. If we take this route, be careful, as any mistakes in generating the DataFrame or the index can cause the data and the index to be aligned incorrectly. In this exercise, the sales DataFrame has been provided for us without the month index. Our job is to build this index separately and then assign it to the sales DataFrame. Before getting started, print the sales DataFrame in the IPython Shell and note that it's missing the month information.

```python
# Generate the list of months: months
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']
# Assign months to sales.index
sales.index=months
# Print the modified sales DataFrame
print(sales)
```

## Extracting data with a MultiIndex
The sales DataFrame we have been working with has been extended to now include State information as well. In the IPython Shell, print the new sales DataFrame to inspect the data. Take note of the MultiIndex! Extracting elements from the outermost level of a MultiIndex is just like in the case of a single-level Index. WE can use the .loc[] accessor.

```python
# Print sales.loc[['CA', 'TX']]
print(sales.loc[['CA', 'TX']])
# Print sales['CA':'TX']
print(sales['CA':'TX'])
```

## Setting & sorting a MultiIndex
In the previous exercise, the MultiIndex was created and sorted. Now, we're going to do this yourself! With a MultiIndex, we should always ensure the index is sorted. We can skip this only if we know the data is already sorted on the index fields.

```python
# Set the index to be the columns ['state', 'month']: sales
sales = sales.set_index(['state', 'month'])
# Sort the MultiIndex: sales
sales = sales.sort_index()
# Print the sales DataFrame
print(sales)
```

## Using .loc[] with nonunique indexes
It is always preferable to have a meaningful index that uniquely identifies each row. Even though pandas does not require unique index values in DataFrames, it works better if the index values are indeed unique. To see an example of this, we will index our sales data by 'state' in this exercise.

```python
# Set the index to the column 'state': sales
sales = sales.set_index('state')
# Print the sales DataFrame
print(sales)
# Access the data from 'NY'
print(sales.loc['NY',:])
```

## Indexing multiple levels of a MultiIndex
Looking up indexed data is fast and efficient. And we have already seen that lookups based on the outermost level of a MultiIndex work just like lookups on DataFrames that have a single-level Index. Looking up data based on inner levels of a MultiIndex can be a bit trickier. In this exercise, we will use your sales DataFrame to do some increasingly complex lookups. The trickiest of all these lookups are when we want to access some inner levels of the index. In this case, we need to use slice(None) in the slicing parameter for the outermost dimension(s) instead of the usual :, or use pd.IndexSlice. We can refer to the pandas documentation for more details. For example, use the following code to extract rows from all Symbols for the dates Oct. 3rd through 4th inclusive:
```
stocks.loc[(slice(None), slice('2016-10-03', '2016-10-04')), :]
```
Pay particular attention to the tuple (slice(None), slice('2016-10-03', '2016-10-04')).

```python
# Look up data for NY in month 1: NY_month1
NY_month1 = sales.loc[('NY',1)]
# Look up data for CA and TX in month 2: CA_TX_month2
CA_TX_month2 = sales.loc[(['CA','TX'],2),:]
# Look up data for all states in month 2: all_month2
all_month2 = sales.loc[(slice(None), 2), :]
```
