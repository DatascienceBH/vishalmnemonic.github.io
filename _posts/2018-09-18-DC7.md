---
title: "Cleaning Data in Python"
date: 2018-09-18
tags: [python]
header:
  images:
excerpt: "Cleaning Data in Python"
---

## Loading and viewing your data
We're going to look at a subset of the Department of Buildings Job Application Filings dataset from the NYC Open Data portal. This dataset consists of job applications filed on January 22, 2017. Our first task is to load this dataset into a DataFrame and then inspect it using the .head() and .tail() methods. However, we'll find out very quickly that the printed results don't allow you to see everything we need, since there are too many columns. Therefore, we need to look at the data in another way. The .shape and .columns attributes let us see the shape of the DataFrame and obtain a list of its columns. From here, we can see which columns are relevant to the questions we'd like to ask of the data. To this end, a new DataFrame, df_subset, consisting only of these relevant columns, has been pre-loaded. This is the DataFrame we'll work with in the rest of the chapter. Get acquainted with the dataset now by exploring it with pandas! This initial exploratory analysis is a crucial first step of data cleaning.

```python
# Import pandas
import pandas as pd
# Read the file into a DataFrame: df
df = pd.read_csv('dob_job_application_filings_subset.csv')
# Print the head of df
print(df.head())
# Print the tail of df
print(df.tail())
# Print the shape of df
print(df.shape)
# Print the columns of df
print(df.columns)
# Print the head and tail of df_subset
print(df_subset.head())
print(df_subset.tail())
```

We identified some potentially unclean or missing data. Now, we'll continue to diagnose our data with the very useful .info() method. The .info() method provides important information about a DataFrame, such as the number of rows, number of columns, number of non-missing values in each column, and the data type stored in each column. This is the kind of information that will allow us to confirm whether the 'Initial Cost' and 'Total Est. Fee' columns are numeric or strings. From the results, we'll also be able to see whether or not all columns have complete data in them. Our task is to use the .info() method on these and analyze the results.

```python
# Print the info of df
print(df.info())
# Print the info of df_subset
print(df_subset.info())
```

## Frequency counts for categorical data
.describe() can only be used on numeric columns. So how can we diagnose data issues when you have categorical data? One way is by using the .value_counts() method, which returns the frequency counts for each unique value in a column! This method also has an optional parameter called dropna which is True by default. What this means is if we have missing data in a column, it will not give a frequency count of them. We want to set the dropna column to False so if there are missing values in a column, it will give us the frequency counts. Here we're going to look at the 'Borough', 'State', and 'Site Fill' columns to make sure all the values in there are valid. When looking at the output, do a sanity check: Are all values in the 'State' column from NY, for example? Since the dataset consists of applications filed in NY, we would expect this to be the case.

```python
# Print the value counts for 'Borough'
print(df['Borough'].value_counts(dropna=False))
# Print the value_counts for 'State'
print(df['State'].value_counts(dropna=False))
# Print the value counts for 'Site Fill'
print(df['Site Fill'].value_counts(dropna=False))
```

## Visualizing single variables with histograms
Up until now, we've been looking at descriptive statistics of our data. One of the best ways to confirm what the numbers are telling us is to plot and visualize the data. We'll start by visualizing single variables using a histogram for numeric values. The column we will work on in this exercise is 'Existing Zoning Sqft'. The .plot() method allows us to create a plot of each column of a DataFrame. The kind parameter allows you to specify the type of plot to use - kind='hist', for example, plots a histogram.

Begin by computing summary statistics for the 'Existing Zoning Sqft' column using the .describe() method. You'll notice that there are extremely large differences between the min and max values, and the plot will need to be adjusted accordingly. In such cases, it's good to look at the plot on a log scale. The keyword arguments logx=True or logy=True can be passed in to .plot() depending on which axis you want to rescale.

Finally, note that Python will render a plot such that the axis will hold all the information. That is, if you end up with large amounts of whitespace in your plot, it indicates counts or values too small to render.

```python
# Import matplotlib.pyplot
import matplotlib.pyplot as plt
# Plot the histogram
df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)
# Display the histogram
plt.show()
```

## Visualizing multiple variables with boxplots
Histograms are great ways of visualizing single variables. To visualize multiple variables, boxplots are useful, especially when one of the variables is categorical. Our job is to use a boxplot to compare the 'initial_cost' across the different values of the 'Borough' column. The pandas .boxplot() method is a quick way to do this, in which we have to specify the column and by parameters. Here, we want to visualize how 'initial_cost' varies by 'Borough'. pandas and matplotlib.pyplot have been imported as pd and plt, respectively, and the DataFrame has been loaded as df.

```python
# Import necessary modules
import pandas as pd
import matplotlib.pyplot as plt
# Create the boxplot
df.boxplot(column='initial_cost', by='Borough', rot=90)
# Display the plot
plt.show()
```

## Visualizing multiple variables with scatter plots
Boxplots are great when we have a numeric column that we want to compare across different categories. When we want to visualize two numeric columns, scatter plots are ideal. Here, our job is to make a scatter plot with 'initial_cost' on the x-axis and the 'total_est_fee' on the y-axis. We can do this by using the DataFrame .plot() method with kind='scatter'. You'll notice right away that there are 2 major outliers shown in the plots. Since these outliers dominate the plot, an additional DataFrame, df_subset, has been provided, in which some of the extreme values have been removed. After making a scatter plot using this, we'll find some interesting patterns here that would not have been seen by looking at summary statistics or 1 variable plots.

```python
# Import necessary modules
import pandas as pd
import matplotlib.pyplot as plt
# Create and display the first scatter plot
df.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)
plt.show()
# Create and display the second scatter plot
df_subset.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)
plt.show()
```

## Reshaping your data using melt
Melting data is the process of turning columns of our data into rows of data. Consider the DataFrames from the previous exercise. In the tidy DataFrame, the variables Ozone, Solar.R, Wind, and Temp each had their own column. If, however, we wanted these variables to be in rows instead, we could melt the DataFrame. In doing so, however, we would make the data untidy! This is important to keep in mind: Depending on how our data is represented, we will have to reshape it differently. Here we will practice melting a DataFrame using pd.melt(). There are two parameters we should be aware of: id_vars and value_vars. The id_vars represent the columns of the data we do not want to melt (i.e., keep it in its current shape), while the value_vars represent the columns we do wish to melt into rows. By default, if no value_vars are provided, all columns not set in the id_vars will be melted. This could save a bit of typing, depending on the number of columns that need to be melted. Our job is to melt its Ozone, Solar.R, Wind, and Temp columns into rows.

```python
# Print the head of airquality
print(airquality.head())
# Melt airquality: airquality_melt
airquality_melt = pd.melt(frame=airquality, id_vars=['Month', 'Day'])
# Print the head of airquality_melt
print(airquality_melt.head())
```

When melting DataFrames, it would be better to have column names more meaningful than variable and value. The default names may work in certain situations, but it's best to always have data that is self explanatory. We can rename the variable column by specifying an argument to the var_name parameter, and the value column by specifying an argument to the value_name parameter.

```python
# Print the head of airquality
print(airquality.head())
# Melt airquality: airquality_melt
airquality_melt = pd.melt(frame=airquality, id_vars=['Month','Day'], var_name='measurement', value_name='reading')
# Print the head of airquality_melt
print(airquality_melt.head())
```

## Pivot data
Pivoting data is the opposite of melting it. Remember the tidy form that the airquality DataFrame was in before we melted it? We'll now begin pivoting it back into that form using the .pivot_table() method! While melting takes a set of columns and turns it into a single column, pivoting will create a new column for each unique value in a specified column. .pivot_table() has an index parameter which we can use to specify the columns that we don't want pivoted: It is similar to the id_vars parameter of pd.melt(). Two other parameters that we have to specify are columns (the name of the column you want to pivot), and values (the values to be used when the column is pivoted).

```python
# Print the head of airquality_melt
print(airquality_melt.head())
# Pivot airquality_melt: airquality_pivot
airquality_pivot = airquality_melt.pivot_table(index=['Month','Day'], columns='measurement', values='reading')
# Print the head of airquality_pivot
print(airquality_pivot.head())
```

After pivoting airquality_melt, we didn't quite get back the original DataFrame. What we got back instead was a pandas DataFrame with a hierarchical index (also known as a MultiIndex). Hierarchical indexes are covered in depth in Manipulating DataFrames with pandas. In essence, they allow us to group columns or rows by another variable - in this case, by 'Month' as well as 'Day'. There's a very simple method we can use to get back the original DataFrame from the pivoted DataFrame: .reset_index().

```python
# Print the index of airquality_pivot
print(airquality_pivot.index)
# Reset the index of airquality_pivot: airquality_pivot
airquality_pivot_reset = airquality_pivot.reset_index()
# Print the new index of airquality_pivot_reset
print(airquality_pivot_reset.index)
# Print the head of airquality_pivot_reset
print(airquality_pivot_reset.head())
```

So far, we've used the .pivot_table() method when there are multiple index values we want to hold constant during a pivot. Let's say our data collection method accidentally duplicated your dataset. Such a dataset, in which each row is duplicated, has been pre-loaded as airquality_dup. In addition, the airquality_melt DataFrame has been pre-loaded. Explore their shapes by accessing their .shape attributes to confirm the duplicate rows present in airquality_dup. We'll see that by using .pivot_table() and the aggfunc parameter, we can not only reshape your data, but also remove duplicates. Finally, we can then flatten the columns of the pivoted DataFrame using .reset_index(). NumPy and pandas have been imported as np and pd respectively.

```python
# Pivot airquality_dup: airquality_pivot
airquality_pivot = airquality_dup.pivot_table(index=['Month','Day'], columns='measurement', values='reading', aggfunc=np.mean)
# Reset the index of airquality_pivot
airquality_pivot = airquality_pivot.reset_index()
# Print the head of airquality_pivot
print(airquality_pivot.head())
# Print the head of airquality
print(airquality.head())
```

## Splitting a column with .str
The dataset consist of case counts of tuberculosis by country, year, gender, and age group, has been pre-loaded into a DataFrame as tb. We're going to tidy the 'm014' column, which represents males aged 0-14 years of age. In order to parse this value, we need to extract the first letter into a new column for gender, and the rest into a column for age_group. Here, since we can parse values by position, we can take advantage of pandas' vectorized string slicing by using the str attribute of columns of type object. Begin by printing the columns of tb in the IPython Shell using its .columns attribute, and take note of the problematic column.

```python
# Melt tb: tb_melt
tb_melt = pd.melt(frame=tb, id_vars=['country','year'])
# Create the 'gender' column
tb_melt['gender'] = tb_melt.variable.str[0]
# Create the 'age_group' column
tb_melt['age_group'] = tb_melt.variable.str[1:]
# Print the head of tb_melt
print(tb_melt.head())
```

## Splitting a column with .split() and .get()
Another common way multiple variables are stored in columns is with a delimiter. We'll learn how to deal with such cases, using a dataset consisting of Ebola cases and death counts by state and country. Print the columns of ebola using ebola.columns. Notice that the data has column names such as Cases_Guinea and Deaths_Guinea. Here, the underscore _ serves as a delimiter between the first part (cases or deaths), and the second part (country). This time, we cannot directly slice the variable by position. We now need to use Python's built-in string method called .split(). By default, this method will split a string into parts separated by a space. However, in this case we want it to split by an underscore. We can do this on Cases_Guinea, for example, using Cases_Guinea.split(' _ '), which returns the list ['Cases', 'Guinea']. The next challenge is to extract the first element of this list and assign it to a type variable, and the second element of the list to a country variable. We can accomplish this by accessing the str attribute of the column and using the .get() method to retrieve the 0 or 1 index, depending on the part we want.

```python
# Melt ebola: ebola_melt
ebola_melt = pd.melt(ebola, id_vars=['Date','Day'], var_name='type_country', value_name='counts')
# Create the 'str_split' column
ebola_melt['str_split'] = ebola_melt['type_country'].str.split('_')
# Create the 'type' column
ebola_melt['type'] = ebola_melt['str_split'].str.get(0)
# Create the 'country' column
ebola_melt['country'] = ebola_melt['str_split'].str.get(1)
# Print the head of ebola_melt
print(ebola_melt.head())
```
