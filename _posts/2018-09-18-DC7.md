---
title: "Cleaning Data in Python"
date: 2018-09-18
tags: [python]
header:
  images:
excerpt: "Cleaning Data in Python"
---

## Loading and viewing your data
We're going to look at a subset of the Department of Buildings Job Application Filings dataset from the NYC Open Data portal. This dataset consists of job applications filed on January 22, 2017. Our first task is to load this dataset into a DataFrame and then inspect it using the .head() and .tail() methods. However, we'll find out very quickly that the printed results don't allow you to see everything we need, since there are too many columns. Therefore, we need to look at the data in another way. The .shape and .columns attributes let us see the shape of the DataFrame and obtain a list of its columns. From here, we can see which columns are relevant to the questions we'd like to ask of the data. To this end, a new DataFrame, df_subset, consisting only of these relevant columns, has been pre-loaded. This is the DataFrame we'll work with in the rest of the chapter. Get acquainted with the dataset now by exploring it with pandas! This initial exploratory analysis is a crucial first step of data cleaning.

```python
# Import pandas
import pandas as pd
# Read the file into a DataFrame: df
df = pd.read_csv('dob_job_application_filings_subset.csv')
# Print the head of df
print(df.head())
# Print the tail of df
print(df.tail())
# Print the shape of df
print(df.shape)
# Print the columns of df
print(df.columns)
# Print the head and tail of df_subset
print(df_subset.head())
print(df_subset.tail())
```

We identified some potentially unclean or missing data. Now, we'll continue to diagnose our data with the very useful .info() method. The .info() method provides important information about a DataFrame, such as the number of rows, number of columns, number of non-missing values in each column, and the data type stored in each column. This is the kind of information that will allow us to confirm whether the 'Initial Cost' and 'Total Est. Fee' columns are numeric or strings. From the results, we'll also be able to see whether or not all columns have complete data in them. Our task is to use the .info() method on these and analyze the results.

```python
# Print the info of df
print(df.info())
# Print the info of df_subset
print(df_subset.info())
```

## Frequency counts for categorical data
.describe() can only be used on numeric columns. So how can we diagnose data issues when you have categorical data? One way is by using the .value_counts() method, which returns the frequency counts for each unique value in a column! This method also has an optional parameter called dropna which is True by default. What this means is if we have missing data in a column, it will not give a frequency count of them. We want to set the dropna column to False so if there are missing values in a column, it will give us the frequency counts. Here we're going to look at the 'Borough', 'State', and 'Site Fill' columns to make sure all the values in there are valid. When looking at the output, do a sanity check: Are all values in the 'State' column from NY, for example? Since the dataset consists of applications filed in NY, we would expect this to be the case.

```python
# Print the value counts for 'Borough'
print(df['Borough'].value_counts(dropna=False))
# Print the value_counts for 'State'
print(df['State'].value_counts(dropna=False))
# Print the value counts for 'Site Fill'
print(df['Site Fill'].value_counts(dropna=False))
```

## Visualizing single variables with histograms
Up until now, we've been looking at descriptive statistics of our data. One of the best ways to confirm what the numbers are telling us is to plot and visualize the data. We'll start by visualizing single variables using a histogram for numeric values. The column we will work on in this exercise is 'Existing Zoning Sqft'. The .plot() method allows us to create a plot of each column of a DataFrame. The kind parameter allows you to specify the type of plot to use - kind='hist', for example, plots a histogram.

Begin by computing summary statistics for the 'Existing Zoning Sqft' column using the .describe() method. You'll notice that there are extremely large differences between the min and max values, and the plot will need to be adjusted accordingly. In such cases, it's good to look at the plot on a log scale. The keyword arguments logx=True or logy=True can be passed in to .plot() depending on which axis you want to rescale.

Finally, note that Python will render a plot such that the axis will hold all the information. That is, if you end up with large amounts of whitespace in your plot, it indicates counts or values too small to render.

```python
# Import matplotlib.pyplot
import matplotlib.pyplot as plt
# Plot the histogram
df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)
# Display the histogram
plt.show()
```
